{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar Notebook 1.2: Character Encoding\n",
    "\n",
    "**LSE MY459: Computational Text Analysis and Large Language Models** (WT 2026)\n",
    "\n",
    "**Ryan HÃ¼bert**\n",
    "\n",
    "This notebook covers character encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory management\n",
    "\n",
    "### A brief primer on directories\n",
    "\n",
    "A [directory](https://en.wikipedia.org/wiki/Directory_(computing)) is a location on your computer that can contain computer files (or other directories). These are commonly referred to as \"folders\" and we will use both terms in this course. On all modern operating systems, directories are arranged in a nested structure. Every directory on a computer can be located using a [path](https://en.wikipedia.org/wiki/Path_(computing)), which is the \"address\" of the directory. Paths look different on Windows and MacOS computers, and you should familiarise yourself with your system's path formatting.\n",
    "\n",
    "Every user account on a modern operating system has a home folder that is the user's top level directory (or their \"root\" directory). For example, on Ryan's computer, the home directory is `/Users/r.hubert/`. This path indicates that Ryan's home directory (or \"folder\") is called \"r.hubert\" and it is located inside of a higher level directory (or a \"parent directory\") called \"Users\". All MacOS computers should use a similar structure for the home folder. In most situations, it does not matter whether you write the path to a directory with a slash at the end or not: `/Users/r.hubert/` and `/Users/r.hubert` are both valid paths for the `r.hubert` directory. In Unix-like operating systems like MacOS and Linux, it is customary to use a tilde to stand for the home folder. So, on Ryan's computer, the path `~` is equivalent to the path `/Users/r.hubert`. On Windows machines, the tilde notation sometimes works but not always.\n",
    "\n",
    "Paths can be used to indicate the locations of directories on a computer, as well as the locations of files on a computer. Typically, files on modern operating systems have file extensions, such as `.docx` for Word documents and `.txt` for plain text documents. Directories do not have such extensions. So, while `/Users/r.hubert/Documents` is a path for the Documents folder, `/Users/r.hubert/Documents/my_file.txt` is a path to a specific file stored inside the Documents folder. On Unix-like machines (and in some contexts on Windows machines) these two paths can also be written `~/Documents` and `~/Documents/my_file.txt`, respectively. \n",
    "\n",
    "All of the paths written here have been _absolute_ paths, meaning that they specify full (or \"absolute\") locations. In some contexts you can use _relative_ paths, which are shortened paths that give the location of a directory or file relative to a current [working directory](https://en.wikipedia.org/wiki/Working_directory). We will almost always use absolute paths in this course because they leave no room for ambiguity. However, you might find it useful to familiarise yourself with the difference by reading the [Wikipedia page](https://en.wikipedia.org/wiki/Path_(computing)).\n",
    "\n",
    "### Managing directories in Python\n",
    "\n",
    "Whenever we need to use Python to read digital data from our computer's storage device(s) or write digital data to our computer's storage device(s), we need to be very careful to specify precisely _where_ we want to read or write data. So, many of the Python notebooks in this course will begin with some _directory management_ where we (1) specify various paths to important locations on our computer where relevant digital data will be read and/or written, and (2) download or copy any necessary files to these locations. In Python, the `os` module has many tools for interacting with an operating system's directory and file system, as you will see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebooks and coding materials from weeks 1 to 7 (and possibly beyond) will use a consistent directory management process. All work will be kept inside a folder called `LSE-MY459-WT26`, which will be located in the home folder. You may choose a different way to organise your materials for the course, but you will need to update the directory management portions of each notebook accordingly. In the next code chunk, we'll use the `os.path.join()` function to create a `str` object that has the full path to this folder. We'll call this object `cdir`, which stands for \"course directory.\" We will then check if that folder exists, and then create it if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T14:11:53.300590Z",
     "start_time": "2026-01-22T14:11:53.241913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the course directory: C:\\Users\\shuyi\\LSE-MY459-WT26\n"
     ]
    }
   ],
   "source": [
    "cdir = os.path.join(os.path.expanduser(\"~\"), \"LSE-MY459-WT26\")\n",
    "\n",
    "## If you want to save your work in a different location, then you can modify the above\n",
    "## For example, if you want your coursework in your \"Documents\" folder, you might choose:\n",
    "# cdir = os.path.join(os.path.expanduser(\"~\"), \"Documents\", \"LSE-MY459-WT26\")\n",
    "\n",
    "print(\"This is the course directory: \" + cdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if the directory (path) exists\n",
    "## If not: then make it using `os.mkdir()`\n",
    "if not os.path.exists(cdir):\n",
    "    os.mkdir(cdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will now define another `str` object that has the full path to the directory where we'll store our work for this week. This directory will be located inside the course directory. We'll call the `str` object `sdir`, to stand for \"seminar directory.\" We do this for convenience, so that we can point Python to the correct location whenever we need to load or save data. We'll also check if the directory exists yet, and if not, we'll create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This week's materials will be stored in: C:\\Users\\shuyi\\LSE-MY459-WT26\\SeminarWeek02\n"
     ]
    }
   ],
   "source": [
    "sdir = os.path.join(cdir, \"SeminarWeek02\")\n",
    "if not os.path.exists(sdir):\n",
    "    os.mkdir(sdir)\n",
    "print(\"This week's materials will be stored in: \" + sdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of directory management, we'll also download any files we will use later in a notebook. There are several files we need this week. The following chunk defines a list with the filenames for each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfiles = [\"general_theory_cover.pdf\", \"methodology-16.txt\", \"methodology-32.txt\", \n",
    "          \"utf-examples-16.txt\", \"utf-examples-32.txt\", \"utf-examples-8.txt\", \n",
    "          \"methodology-8.txt\", \"shanghai.txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will download all the required files and put them into the `sdir` folder you specified above. It uses a loop that iterates over each of these files, constructs a URL to the file's location on GitHub, makes an [HTTP request](https://en.wikipedia.org/wiki/HTTP) for the file, and then saves the response to `sdir`. We will use the `requests` module to make the HTTP requests to download the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time   # to embed delays in the loop\n",
    "\n",
    "for f in sfiles:\n",
    "    # Where is the remote file?\n",
    "    rfile = \"https://raw.githubusercontent.com/lse-my459/data/master/\" + f\n",
    "    \n",
    "    # Where will we store the local copy of it?\n",
    "    lfile = os.path.join(sdir, f)\n",
    "    \n",
    "    # Check if you have the file yet and if not, download it to correct location\n",
    "    if not os.path.exists(lfile):\n",
    "        r = requests.get(rfile) # make GET request for the remote file\n",
    "        r.raise_for_status()    # raise exception if there's an HTTP error\n",
    "        \n",
    "        # Write the raw bytes received from the server to the local file path\n",
    "        with open(lfile, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        \n",
    "        time.sleep(1) # Pause for 1 second so you do not overwhelm server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Encoding\n",
    "\n",
    "While Python internally represents characters as Unicode code points, that is not how characters are typically stored in files. When Python reads a (text) file, it has to _decode_ the bytes into code points (`str` objects), and when it saves text into a file, it needs to _encode_ the code points into bytes. You can read more about it here: <https://docs.python.org/3/library/codecs.html#encodings-and-unicode>.\n",
    "\n",
    "Python has a method for encoding strings to bytes, and a method for decoding bytes to strings. First, let's take a string with an accented character and encode it to bytes using the UTF-8 encoding standard. You will notice that a `bytes` object is echoed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'M\\xc3\\xa9xico'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"MÃ©xico\".encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to see binary instead of a Python `bytes` object, we can use a [list comprehension](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions) to echo each byte's binary. **Note**: you absolutely _must_ understand and be able to use `list`, `dict`, and `set` comprehensions in this course! You can read about `list` comprehensions here (and the same principles apply for `dict` and `set` comprehensions): <https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01001101',\n",
       " '11000011',\n",
       " '10101001',\n",
       " '01111000',\n",
       " '01101001',\n",
       " '01100011',\n",
       " '01101111']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[format(x, \"08b\") for x in \"MÃ©xico\".encode(\"utf-8\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go the other way. We'll take raw bytes and then decode them into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MÃ©xico'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b'M\\xc3\\xa9xico'.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the `decode()` method becomes even more obvious when you start with raw bytes that are _all_ hex codes. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ã‚ã‚ŠãŒã¨ã†'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b'\\xe3\\x81\\x82\\xe3\\x82\\x8a\\xe3\\x81\\x8c\\xe3\\x81\\xa8\\xe3\\x81\\x86'.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those raw bytes are the UTF-8 encoded bytes corresponding to the characters that create the Japanese word for \"thank you.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing encoded files\n",
    "\n",
    "To reiterate an important point from lecture: raw bytes (like those in the previous code chunk) are what is stored in a text file. When you use software to save text into files or read text from files, you have to make a decision about how to encode the characters into bytes or decode the bytes into characters. In most situations, a user is not aware that they are making this choice because most modern software makes the choice for you. For example, suppose we have the following text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_text = \"MY459 is very interesting and lots of fun!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to write this text to a plain text file called `MY459_fun.txt`. Then, we would use the built in [`open()` function](https://docs.python.org/3/library/functions.html#open) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(sdir, \"MY459_fun.txt\"), \"w\") as f:\n",
    "    f.write(fun_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above took the string in Python's scope, encoded it to bytes and then wrote those bytes to a file. But since we did not tell Python _how_ to encode the string into bytes, it chose an encoding for us. As the [documentation](https://docs.python.org/3/library/functions.html#open) spells out, Python will use a computer's system default encoding. How do you know what you system default is? If your computer is relatively new and it was purchased in a country that uses a Latin-based alphabet, then it almost certainly UTF-8. But you can check in Python using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This computer's default encoding is: utf-8\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "print(\"This computer's default encoding is: \" + locale.getpreferredencoding(False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this class, we will encode all files as UTF-8. We'll also (try) to get into the habit of specifying UTF-8 when we read or write text, so that we do not let Python choose for us (and possibly do weird things we don't notice). Indeed, UTF-8 has become the default encoding across the world, and it is generally good practice to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character encoding and file size\n",
    "\n",
    "Since UTF-8 is a variable width encoding, the number of bytes you write might not be equal to the number of characters in the text. For example, if we write a word to a text file that only contains the [original ASCII characters](https://en.wikipedia.org/wiki/ASCII#Character_set), then each character will take one byte, and the file size (in bytes) will equal the number of characters. (Note: on Windows machines, this may not be true, depending on your set up.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(sdir, \"mexico1.txt\"), mode = \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Mexico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the file size in your operating system's file browser, or you can use the `os` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(os.path.join(sdir, \"mexico1.txt\")) # file size in bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But suppose we have a string that has a character beyond the set of original ASCII characters. For example: suppose we have a string with an accented character. Then, some characters will be encoded to more than one byte, and the file size will be greater than the number of characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(sdir, \"mexico2.txt\"), mode = \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"MÃ©xico\")\n",
    "os.path.getsize(os.path.join(sdir, \"mexico2.txt\")) # file size in bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the files in `sdir`, you will notice that `mexico1.txt` has one fewer byte than `mexico2.txt`. (Again, this is true on MacOS, and may be slightly different on Windows.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider a second example. I wrote \"&uÃ¼Ð”áˆŠðŸ« \" into three text files using different encodings:\n",
    "\n",
    "- `utf-examples-8.txt` (UTF-8): 13 bytes\n",
    "- `utf-examples-16.txt` (UTF-16): 16 bytes\n",
    "- `utf-examples-32.txt` (UTF-32): 28 bytes\n",
    "\n",
    "Note that the UTF-32 encoded file is more than double the size of UTF-8 (storing the same six characters!):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å­—æ¯ 1 byte\n",
    "emoji 4 bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(os.path.join(sdir, \"utf-examples-8.txt\")) # file size in bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(os.path.join(sdir, \"utf-examples-16.txt\")) # file size in bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(os.path.join(sdir, \"utf-examples-32.txt\")) # file size in bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try to open them. The UTF-8 file opens just fine if we do not specify an encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&uÃ¼Ð”áˆŠðŸ« '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(sdir, \"utf-examples-8.txt\"), mode = \"r\") as f:\n",
    "    utf8_str = f.read()\n",
    "utf8_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the UTF-16 file does not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(sdir, \u001b[33m\"\u001b[39m\u001b[33mutf-examples-16.txt\u001b[39m\u001b[33m\"\u001b[39m), mode = \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     utf16_str = \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:322\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(sdir, \"utf-examples-16.txt\"), mode = \"r\") as f:\n",
    "    utf16_str = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, the error message here is informative. It tells us that Python attempted to open the file using UTF-8 encoding (the system default), but then encountered a byte that didn't seem like it was UTF-8 encoded. Since we know it is UTF-16 encoding, let's make sure we specify this when trying to read the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&uÃ¼Ð”áˆŠðŸ« '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(sdir, \"utf-examples-16.txt\"), mode = \"r\", encoding = \"UTF-16\") as f:\n",
    "    utf16_str = f.read()\n",
    "utf16_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the six characters were encoded differently in the files (with different numbers of bytes), when they are decoded during the open process (by the `open()` function), they yield identical sequences of unicode code points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utf8_str == utf16_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fully understand what's going on, let's now read in the raw bytes from both files by setting `mode = \"rb\"` and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "binary mode doesn't take an encoding argument",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-examples-8.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      2\u001b[39m     utf8_bytes = f.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/lse-my459/lib/python3.12/site-packages/IPython/core/interactiveshell.py:344\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    339\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    342\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: binary mode doesn't take an encoding argument"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(sdir, \"utf-examples-8.txt\"), mode = \"rb\", encoding=\"utf-8\") as f:\n",
    "    utf8_bytes = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we receive an error! Thinking back to the lecture material on character encoding, do we get an error when we try to include an encoding with `mode='rb'`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'&u\\xc3\\xbc\\xd0\\x94\\xe1\\x88\\x8a\\xf0\\x9f\\xab\\xa0'\n",
      "b'\\xff\\xfe&\\x00u\\x00\\xfc\\x00\\x14\\x04\\n\\x12>\\xd8\\xe0\\xde'\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(sdir, \"utf-examples-8.txt\"), mode = \"rb\") as f:\n",
    "    utf8_bytes = f.read()\n",
    "print(utf8_bytes)\n",
    "with open(os.path.join(sdir, \"utf-examples-16.txt\"), mode = \"rb\") as f:\n",
    "    utf16_bytes = f.read()\n",
    "print(utf16_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we get mostly hex codes, but we also get some other ASCII characters. How many bytes did we read into Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(utf8_bytes))\n",
    "print(len(utf16_bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what happens when we read in the UTF-32 encoded bytes _for the same characters_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xff\\xfe\\x00\\x00&\\x00\\x00\\x00u\\x00\\x00\\x00\\xfc\\x00\\x00\\x00\\x14\\x04\\x00\\x00\\n\\x12\\x00\\x00\\xe0\\xfa\\x01\\x00'\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(sdir, \"utf-examples-32.txt\"), mode = \"rb\") as f:\n",
    "    utf32_bytes = f.read()\n",
    "print(utf32_bytes)\n",
    "print(len(utf32_bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guessing encodings\n",
    "\n",
    "Finally, let's look at some Chinese characters. We will try to read a file containing the Chinese-language word \"ä¸Šæµ·\" (Shanghai), which is encoded with the [GB_18030](https://en.wikipedia.org/wiki/GB_18030) encoding. Let's pretend that we don't know the document's encoding and we are trying to load it into Python. If we do not specify an encoding in the `open()` function, then Python will use the system default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc9 in position 0: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(sdir, \u001b[33m\"\u001b[39m\u001b[33mshanghai.txt\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:322\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xc9 in position 0: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(sdir, \"shanghai.txt\"), \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try to guess an encoding. For example, what if we try to use the [ISO-8859-1 encoding](https://en.wikipedia.org/wiki/ISO/IEC_8859-1) (sometimes called \"Latin 1\"), which was the first extension of the 7-bit ASCII encoding to 8-bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã‰ÃÂºÂ£\n"
     ]
    }
   ],
   "source": [
    "# This prints garbled characters (mojibake) when read with wrong encoding\n",
    "with open(os.path.join(sdir, \"shanghai.txt\"), \"r\", encoding=\"ISO-8859-1\") as f: # encoding=\"latin-1\" gives same result\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that it returns a sequence of characters that look like mojibake, so clearly this is the wrong encoding. Why don't we try \"UTF-16\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeError",
     "evalue": "UTF-16 stream does not start with BOM",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(sdir, \u001b[33m\"\u001b[39m\u001b[33mshanghai.txt\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-16\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:322\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/lse-my459/lib/python3.12/encodings/utf_16.py:67\u001b[39m, in \u001b[36mIncrementalDecoder._buffer_decode\u001b[39m\u001b[34m(self, input, errors, final)\u001b[39m\n\u001b[32m     65\u001b[39m         \u001b[38;5;28mself\u001b[39m.decoder = codecs.utf_16_be_decode\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m consumed >= \u001b[32m2\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUTF-16 stream does not start with BOM\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (output, consumed)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.decoder(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m.errors, final)\n",
      "\u001b[31mUnicodeError\u001b[39m: UTF-16 stream does not start with BOM"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(sdir, \"shanghai.txt\"), \"r\", encoding=\"utf-16\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we get an encoding error, indicating that the raw bytes are not structured in a way that \"looks like\" UTF-16. Specifically, when Python assumes UTF-16 encoding, it expects to see a [byte order mark (BOM)](https://en.wikipedia.org/wiki/Byte_order_mark) indicating whether the encoding is \"big-endian\" or \"little-endian\". \n",
    "\n",
    "Maybe the command line can help? Here's the Terminal output from Ryan's machine:\n",
    "\n",
    "```bash\n",
    "r.hubert@LSE-Mac-r ~ % cd LSE-MY459-WT26/SeminarWeek02 \n",
    "r.hubert@LSE-Mac-r SeminarWeek02 % file -I shanghai.txt\n",
    "shanghai.txt: text/plain; charset=iso-8859-1\n",
    "```\n",
    "\n",
    "The command line can't help here: it guesses the encoding is ISO-8859-1. Clearly this is not correct, as we saw above!\n",
    "\n",
    "Let's try using a tool available in Python via the `charset_normalizer` module. First, we read the file data into R as raw bytes, then we attempt to guess the encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xc9\\xcf\\xba\\xa3'\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(sdir, \"shanghai.txt\"), \"rb\") as f:\n",
    "    unknown_data = f.read()\n",
    "print(unknown_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'Big5', 'language': 'Chinese', 'confidence': 0.8}\n"
     ]
    }
   ],
   "source": [
    "import charset_normalizer\n",
    "print(charset_normalizer.detect(unknown_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output suggests that `charset_normalizer` thinks this is [Big5 encoding](https://en.wikipedia.org/wiki/Big5). Let's try to read the file with that encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¥»æ¼†\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(sdir, \"shanghai.txt\"), \"r\", encoding=\"Big5\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now get Chinese characters, but these characters together do not make sense. I can look at the text file on my computer and see \"â€¦Å“âˆ«Â£\". Obviously that's not right either. What a nightmare! \n",
    "\n",
    "What should you do next? This is a process of trial and error. For example, if you read the [Wikipedia page on Big5](https://en.wikipedia.org/wiki/Big5), you'll see a reference on the page to [GB 18030](https://en.wikipedia.org/wiki/GB_18030), another common encoding standard for Chinese characters. On a hunch, why don't we try it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸Šæµ·\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(sdir, \"shanghai.txt\"), \"r\", encoding=\"gb18030\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These characters now _do_ make sense, and they say \"Shanghai.\" If you are lucky enough to figure out a file's encoding, you should always save a new version encoded in a more standard encoding, like UTF-8. You might even consider using a file name indicating it is encoded with UTF-8 so that the next person will thank you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read with correct encoding and save as UTF-8\n",
    "with open(os.path.join(sdir, \"shanghai.txt\"), \"r\", encoding=\"gb18030\") as f:\n",
    "    shanghai = f.read()\n",
    "with open(os.path.join(sdir, \"shanghai_utf-8.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(shanghai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸Šæµ·\n"
     ]
    }
   ],
   "source": [
    "# Now that we've saved with UTF-8 encoding, let's see how much easier it is to read the file:\n",
    "with open(os.path.join(sdir, \"shanghai_utf-8.txt\"), \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that we no longer have to specify an encoding (UTF-8 is the default in Python 3), and it is. We get the expected text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing PDFs\n",
    "\n",
    "A common question, e.g. when analysing scans of old books, is how to read/parse the textual content of PDFs into programming languages such as R or Python. For Python, the package `pypdf` (or `PyPDF2`) can be used to extract text from PDFs containing machine-readable text, and `pytesseract` can be used for OCR on image-based PDFs. Here, we will cover extraction of text from PDFs containing machine-readable text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDFs containing text\n",
    "\n",
    "To demonstrate how to extract text from a PDF, we will work with a famous 1687 book by Sir Isaac Newton titled [_PhilosophiÃ¦ Naturalis Principia Mathematica_](https://en.wikipedia.org/wiki/Philosophi%C3%A6_Naturalis_Principia_Mathematica), but commonly referred to as Newton's _Principia_. We'll examine its English translation. You can obtain the book from Google Books by clicking on \"Download PDF\" at this webpage: <https://www.google.co.uk/books/edition/Newton_s_Principia/KaAIAAAAIAAJ>. Once you have downloadedÂ the file, move it to `sdir`.\n",
    "\n",
    "Next, we read the text of the PDF into Python using the following. Note that this leaves us with a list called `principia`, where every element is a `str` object containing the text from a specific page of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'list'>\n",
      "Number of pages: 607\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(os.path.join(sdir, \"Newton_s_Principia.pdf\"))\n",
    "\n",
    "principia = [page.extract_text() for page in reader.pages]\n",
    "\n",
    "print(f\"Type: {type(principia)}\")\n",
    "print(f\"Number of pages: {len(principia)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the first nine pages contain no text, we will delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages after trimming: 598\n"
     ]
    }
   ],
   "source": [
    "# We now delete the first few pages, which, as you can see in the PDF, have no important text.\n",
    "principia = principia[9:]\n",
    "\n",
    "print(f\"Number of pages after trimming: {len(principia)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's view the first page of the text that we have in our list object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEWTON'S PRINCIPIA .\n",
      "THE\n",
      "MATHEMATICAL PRINCIPLES\n",
      "OF\n",
      "NATURAL PHILOSOPHY ,\n",
      "BY SIR ISAAC NEWTON ;\n",
      "TRANSLATED INTO ENGLISH BY ANDREW MOTTE .\n",
      "TO WHICH IS ADDED\n",
      "NEWTON'S SYSTEM OF THE WORLD ;\n",
      "With a PortraittakenfromtheBustintheRoyalObservatoryatGreenwich.\n",
      "FIRST AMERICAN EDITION , CAREFULLY REVISED AND CORRECTED ,\n",
      "WITH A LIFE OF THE AUTHOR , BY N. W. CHITTENDEN , M. A., & c.\n",
      "TOR LIBRAR\n",
      "NEW YORK :\n",
      "PUBLISHED BY DANIEL ADEE , 107 FULTON STREET .\n",
      "1848 .\n"
     ]
    }
   ],
   "source": [
    "print(principia[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When taking text from scans, software usually creates manual line breaks based on where the line visually appears to end on a page. These line breaks usually have little meaning for text analysis, and just create messier, more cumbersome (and sometimes larger) files. We'll clean things up by deleting the manual line breaks. (Note: Windows machines often use `\\r\\n` for line breaks, whereas Unix-like machines use `\\n`. So, we will replace both.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEWTON'S PRINCIPIA . THE MATHEMATICAL PRINCIPLES OF NATURAL PHILOSOPHY , BY SIR ISAAC NEWTON ; TRANSLATED INTO ENGLISH BY ANDREW MOTTE . TO WHICH IS ADDED NEWTON'S SYSTEM OF THE WORLD ; With a PortraittakenfromtheBustintheRoyalObservatoryatGreenwich. FIRST AMERICAN EDITION , CAREFULLY REVISED AND CORRECTED , WITH A LIFE OF THE AUTHOR , BY N. W. CHITTENDEN , M. A., & c. TOR LIBRAR NEW YORK : PUBLISHED BY DANIEL ADEE , 107 FULTON STREET . 1848 .\n"
     ]
    }
   ],
   "source": [
    "# Remove line breaks using regular expressions\n",
    "principia_cleaned = [page.replace(\"\\r\\n\", \" \") for page in principia]\n",
    "principia_cleaned = [page.replace(\"\\n\", \" \") for page in principia_cleaned]\n",
    "\n",
    "# Let's see a sample of the first page\n",
    "print(principia_cleaned[0][:500] if principia_cleaned[0] else \"No text extracted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lse-my459",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
