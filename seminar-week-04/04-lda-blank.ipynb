{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar Notebook 2.4: Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "**LSE MY459: Computational Text Analysis and Large Language Models** (WT 2026)\n",
    "\n",
    "**Ryan H\u00fcbert**\n",
    "\n",
    "This notebook covers Latent Dirichlet Allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory management\n",
    "\n",
    "We begin with some directory management to specify the file path to the folder on your computer where you wish to store data for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the DFM\n",
    "\n",
    "We need to load the DFM we created in the last notebook. We start by reading the sparse array object we saved as an `.npz` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load the list of features (the vocabulary), which remember is not included with the sparse array data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "We will run LDA on our corpus of news articles. We'll estimate 10 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was the case for $k$-means clustering, we are interested in each document $i$'s $\\widehat{\\boldsymbol{\\pi}}_i$, as well as each cluster $k$'s $\\widehat{\\boldsymbol{\\mu}}_k$. However in the context of topic modelling, they have different interpretations:\n",
    "\n",
    "- $\\widehat{\\boldsymbol{\\pi}}_i$ gives the proportion of document $i$ that corresponds to each topic\n",
    "- $\\widehat{\\boldsymbol{\\mu}}_k$ gives the word use for a topic $k$\n",
    "\n",
    "Where can we extract these important items from the `lda` object?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic assignment proportions \n",
    "\n",
    "We can extract each document's topic proportions as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we see that document 0 has the following proportions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document is 40% about topic 0, 24% about topic 3, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic feature probabilities (word use)\n",
    "\n",
    "Next, we need to examine what these topics are actually about. We begin by extracting a $K \\times J$ matrix (in our case $10 \\times 6236$), where each row gives a topic's $\\widehat{\\boldsymbol{\\mu}}_k$. In the DGP for LDA, this parameter controls the probabilities that each token in the vocabulary will be chosen when a token is assigned to that topic. The following code extracts this $\\widehat{\\boldsymbol{\\mu}}$ matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a specific topic's word usage by extracting a row of this matrix, such as topic 0 (the \"first\" topic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each topic, we can use the topic's row in `mu` to find the top words of that cluster. More specifically, the words used the most in the cluster's centroid. Consider cluster 0. First, let's figure out which of the elements of $\\boldsymbol{\\mu}_0$ represent the 6 most used words in this cluster's centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know what each of the 10 topics are roughly about. So we can look at the top features for each topic $k$, as represented by the feature with the highest probability in $\\boldsymbol{\\mu}_k$. This is identical to what we did for $k$-means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading documents\n",
    "\n",
    "Of course, if you want to really understand these topics, you will need to read a selection of documents corresponding to each one of the topics. Let's look at the five documents that have the highest proportion of tokens assigned to a topic. First, let's identify the top five documents for each topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load the corpus documents and look at the top five documents in topic 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could, of course, do the same thing to review clusters as well!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lse-my459",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}