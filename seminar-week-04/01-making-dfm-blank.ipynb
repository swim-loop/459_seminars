{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar Notebook 2.1: Making a DFM\n",
    "\n",
    "**LSE MY459: Computational Text Analysis and Large Language Models** (WT 2026)\n",
    "\n",
    "**Ryan Hübert**\n",
    "\n",
    "This notebook covers creating a DFM using a corpus of news articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory management\n",
    "\n",
    "We begin with some directory management to specify the file path to the folder on your computer where you wish to store data for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "sdir = os.path.join(os.path.expanduser(\"~\"), \"LSE-MY459-WT26\", \"SeminarWeek04\")\n",
    "if not os.path.exists(sdir):\n",
    "    os.mkdir(sdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by loading a corpus of news articles published in the Guardian during 2016. This corpus was sourced from the `{quanteda}` R package, see: <https://tutorials.quanteda.io/machine-learning/topicmodel/>. You can get a `.csv` version of the file from the `data` repo in the course GitHub. The following code chunk will download this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfile = 'https://raw.githubusercontent.com/lse-my459/data/refs/heads/main/corpus_guardian_2016.csv'\n",
    "lfile = os.path.join(sdir, os.path.basename(rfile))\n",
    "if not os.path.exists(lfile):\n",
    "    import requests\n",
    "    r = requests.get(rfile)\n",
    "    r.raise_for_status()\n",
    "    with open(rfile, \"wb\") as f: #要记住WB是什么，raw bites\n",
    "        f.write(r.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preprocessing the corpus\n",
    "\n",
    "In the next cell, we load and clean the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuyi\\AppData\\Local\\Temp\\ipykernel_25320\\3694855734.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  tf[\"datetime\"] = pd.to_datetime(tf[\"datetime\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 17:24:00</td>\n",
       "      <td>A second man has died as a result of heavy flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 18:37:00</td>\n",
       "      <td>As tensions continue in Chicago over the handl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 22:01:00</td>\n",
       "      <td>Academic journals have begun withholding the g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04 00:50:00</td>\n",
       "      <td>The brutal propaganda video released by Islami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-04 10:59:00</td>\n",
       "      <td>A cache of 13 weapons has been discovered in t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime                                              texts\n",
       "0 2016-01-01 17:24:00  A second man has died as a result of heavy flo...\n",
       "1 2016-01-01 18:37:00  As tensions continue in Chicago over the handl...\n",
       "2 2016-01-01 22:01:00  Academic journals have begun withholding the g...\n",
       "3 2016-01-04 00:50:00  The brutal propaganda video released by Islami...\n",
       "4 2016-01-04 10:59:00  A cache of 13 weapons has been discovered in t..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tf = pd.read_csv(lfile, dtype= \"object\") #要有dtype, full contorl, raw string\n",
    "tf[\"datetime\"] = tf[\"date\"] + \" \" + tf[\"edition\"]\n",
    "tf[\"datetime\"] = tf[\"datetime\"].str.replace(\"GMT\", \"\")\n",
    "tf[\"datetime\"] = pd.to_datetime(tf[\"datetime\"])\n",
    "tf = tf.loc[:,['datetime','texts']]\n",
    "tf = tf.sort_values(\"datetime\") #如果时间是string的话不能正确的sort\n",
    "tf = tf.reset_index(drop=True)\n",
    "tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will work through standard pre-processing steps. Keep in mind that we are looking at a corpus of news articles, and that may affect how we pre-process. Let's start by tokenising on white space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>texts</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 17:24:00</td>\n",
       "      <td>A second man has died as a result of heavy flo...</td>\n",
       "      <td>[A, second, man, has, died, as, a, result, of,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 18:37:00</td>\n",
       "      <td>As tensions continue in Chicago over the handl...</td>\n",
       "      <td>[As, tensions, continue, in, Chicago, over, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 22:01:00</td>\n",
       "      <td>Academic journals have begun withholding the g...</td>\n",
       "      <td>[Academic, journals, have, begun, withholding,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04 00:50:00</td>\n",
       "      <td>The brutal propaganda video released by Islami...</td>\n",
       "      <td>[The, brutal, propaganda, video, released, by,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-04 10:59:00</td>\n",
       "      <td>A cache of 13 weapons has been discovered in t...</td>\n",
       "      <td>[A, cache, of, 13, weapons, has, been, discove...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime                                              texts  \\\n",
       "0 2016-01-01 17:24:00  A second man has died as a result of heavy flo...   \n",
       "1 2016-01-01 18:37:00  As tensions continue in Chicago over the handl...   \n",
       "2 2016-01-01 22:01:00  Academic journals have begun withholding the g...   \n",
       "3 2016-01-04 00:50:00  The brutal propaganda video released by Islami...   \n",
       "4 2016-01-04 10:59:00  A cache of 13 weapons has been discovered in t...   \n",
       "\n",
       "                                        preprocessed  \n",
       "0  [A, second, man, has, died, as, a, result, of,...  \n",
       "1  [As, tensions, continue, in, Chicago, over, th...  \n",
       "2  [Academic, journals, have, begun, withholding,...  \n",
       "3  [The, brutal, propaganda, video, released, by,...  \n",
       "4  [A, cache, of, 13, weapons, has, been, discove...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf[\"preprocessed\"] = tf[\"texts\"].str.split(r\"\\s+\") #根据空格\n",
    "tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we make all words lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>texts</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 17:24:00</td>\n",
       "      <td>A second man has died as a result of heavy flo...</td>\n",
       "      <td>[a, second, man, has, died, as, a, result, of,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 18:37:00</td>\n",
       "      <td>As tensions continue in Chicago over the handl...</td>\n",
       "      <td>[as, tensions, continue, in, chicago, over, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 22:01:00</td>\n",
       "      <td>Academic journals have begun withholding the g...</td>\n",
       "      <td>[academic, journals, have, begun, withholding,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04 00:50:00</td>\n",
       "      <td>The brutal propaganda video released by Islami...</td>\n",
       "      <td>[the, brutal, propaganda, video, released, by,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-04 10:59:00</td>\n",
       "      <td>A cache of 13 weapons has been discovered in t...</td>\n",
       "      <td>[a, cache, of, 13, weapons, has, been, discove...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime                                              texts  \\\n",
       "0 2016-01-01 17:24:00  A second man has died as a result of heavy flo...   \n",
       "1 2016-01-01 18:37:00  As tensions continue in Chicago over the handl...   \n",
       "2 2016-01-01 22:01:00  Academic journals have begun withholding the g...   \n",
       "3 2016-01-04 00:50:00  The brutal propaganda video released by Islami...   \n",
       "4 2016-01-04 10:59:00  A cache of 13 weapons has been discovered in t...   \n",
       "\n",
       "                                        preprocessed  \n",
       "0  [a, second, man, has, died, as, a, result, of,...  \n",
       "1  [as, tensions, continue, in, chicago, over, th...  \n",
       "2  [academic, journals, have, begun, withholding,...  \n",
       "3  [the, brutal, propaganda, video, released, by,...  \n",
       "4  [a, cache, of, 13, weapons, has, been, discove...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf[\"preprocessed\"] = tf[\"preprocessed\"].apply(lambda doc_tokens: [x.lower() for x in doc_tokens])\n",
    "tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will clean up the text by removing extraneous punctuation, and dropping tokens we don't want. There is a lot of possible analyst discretion about how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A second man has died as a result of heavy flo...</td>\n",
       "      <td>[a, second, man, has, died, as, a, result, of,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As tensions continue in Chicago over the handl...</td>\n",
       "      <td>[as, tensions, continue, in, chicago, over, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Academic journals have begun withholding the g...</td>\n",
       "      <td>[academic, journals, have, begun, withholding,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The brutal propaganda video released by Islami...</td>\n",
       "      <td>[the, brutal, propaganda, video, released, by,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A cache of 13 weapons has been discovered in t...</td>\n",
       "      <td>[a, cache, of, weapons, has, been, discovered,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  \\\n",
       "0  A second man has died as a result of heavy flo...   \n",
       "1  As tensions continue in Chicago over the handl...   \n",
       "2  Academic journals have begun withholding the g...   \n",
       "3  The brutal propaganda video released by Islami...   \n",
       "4  A cache of 13 weapons has been discovered in t...   \n",
       "\n",
       "                                        preprocessed  \n",
       "0  [a, second, man, has, died, as, a, result, of,...  \n",
       "1  [as, tensions, continue, in, chicago, over, th...  \n",
       "2  [academic, journals, have, begun, withholding,...  \n",
       "3  [the, brutal, propaganda, video, released, by,...  \n",
       "4  [a, cache, of, weapons, has, been, discovered,...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Replace brackets\n",
    "tf[\"preprocessed\"] = tf[\"preprocessed\"].apply(lambda doc_tokens: [re.sub(r\"(^[\\[\\(\\{]|[\\]\\)\\}]$)\",\"\", x) for x in doc_tokens])\n",
    "# Keep only tokens that begin with a letter\n",
    "tf[\"preprocessed\"] = tf[\"preprocessed\"].apply(lambda doc_tokens: [x for x in doc_tokens if re.search(r\"^[A-Za-z]\", x)])\n",
    "# Keep only tokens that have no numbers in them\n",
    "tf[\"preprocessed\"] = tf[\"preprocessed\"].apply(lambda doc_tokens: [x for x in doc_tokens if not re.search(r\"[0-9]\", x)])\n",
    "# Remove all other punctuation, except dashes and apostrophes\n",
    "tf[\"preprocessed\"] = tf[\"preprocessed\"].apply(lambda doc_tokens: [re.sub(r'[^A-Za-z\\-\\']', '', x) for x in doc_tokens])\n",
    "# Drop strings with article publishing time info\n",
    "tf[\"preprocessed\"] = tf[\"preprocessed\"].apply(lambda doc_tokens: [x for x in doc_tokens if not re.search(r\"^(.*\\-time|updated\\-.*|gmt|bst)$\", x)])\n",
    "# Drop empty strings\n",
    "tf[\"preprocessed\"] = tf[\"preprocessed\"].apply(lambda doc_tokens: [x for x in doc_tokens if x != \"\"])\n",
    "tf.loc[:,[\"texts\", \"preprocessed\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove English stop words from this corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>texts</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 17:24:00</td>\n",
       "      <td>A second man has died as a result of heavy flo...</td>\n",
       "      <td>[second, man, died, result, heavy, flooding, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 18:37:00</td>\n",
       "      <td>As tensions continue in Chicago over the handl...</td>\n",
       "      <td>[tensions, continue, chicago, handling, police...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 22:01:00</td>\n",
       "      <td>Academic journals have begun withholding the g...</td>\n",
       "      <td>[academic, journals, begun, withholding, geogr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04 00:50:00</td>\n",
       "      <td>The brutal propaganda video released by Islami...</td>\n",
       "      <td>[brutal, propaganda, video, released, islamic,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-04 10:59:00</td>\n",
       "      <td>A cache of 13 weapons has been discovered in t...</td>\n",
       "      <td>[cache, weapons, discovered, possession, gunma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime                                              texts  \\\n",
       "0 2016-01-01 17:24:00  A second man has died as a result of heavy flo...   \n",
       "1 2016-01-01 18:37:00  As tensions continue in Chicago over the handl...   \n",
       "2 2016-01-01 22:01:00  Academic journals have begun withholding the g...   \n",
       "3 2016-01-04 00:50:00  The brutal propaganda video released by Islami...   \n",
       "4 2016-01-04 10:59:00  A cache of 13 weapons has been discovered in t...   \n",
       "\n",
       "                                        preprocessed  \n",
       "0  [second, man, died, result, heavy, flooding, s...  \n",
       "1  [tensions, continue, chicago, handling, police...  \n",
       "2  [academic, journals, begun, withholding, geogr...  \n",
       "3  [brutal, propaganda, video, released, islamic,...  \n",
       "4  [cache, weapons, discovered, possession, gunma...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words(\"english\")\n",
    "sw = [x.lower() for x in sw]\n",
    "\n",
    "tf[\"preprocessed\"] = tf[\"preprocessed\"].apply(lambda doc_tokens: [x for x in doc_tokens if x not in sw])\n",
    "tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will use the Snowball stemmer to create equivalence classes of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>texts</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 17:24:00</td>\n",
       "      <td>A second man has died as a result of heavy flo...</td>\n",
       "      <td>[second, man, die, result, heavi, flood, scotl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 18:37:00</td>\n",
       "      <td>As tensions continue in Chicago over the handl...</td>\n",
       "      <td>[tension, continu, chicago, handl, polic, shoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 22:01:00</td>\n",
       "      <td>Academic journals have begun withholding the g...</td>\n",
       "      <td>[academ, journal, begun, withhold, geograph, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04 00:50:00</td>\n",
       "      <td>The brutal propaganda video released by Islami...</td>\n",
       "      <td>[brutal, propaganda, video, relea, islam, stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-04 10:59:00</td>\n",
       "      <td>A cache of 13 weapons has been discovered in t...</td>\n",
       "      <td>[cach, weapon, discov, possess, gunman, open, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime                                              texts  \\\n",
       "0 2016-01-01 17:24:00  A second man has died as a result of heavy flo...   \n",
       "1 2016-01-01 18:37:00  As tensions continue in Chicago over the handl...   \n",
       "2 2016-01-01 22:01:00  Academic journals have begun withholding the g...   \n",
       "3 2016-01-04 00:50:00  The brutal propaganda video released by Islami...   \n",
       "4 2016-01-04 10:59:00  A cache of 13 weapons has been discovered in t...   \n",
       "\n",
       "                                        preprocessed  \n",
       "0  [second, man, die, result, heavi, flood, scotl...  \n",
       "1  [tension, continu, chicago, handl, polic, shoo...  \n",
       "2  [academ, journal, begun, withhold, geograph, l...  \n",
       "3  [brutal, propaganda, video, relea, islam, stat...  \n",
       "4  [cach, weapon, discov, possess, gunman, open, ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import snowball\n",
    "sstemmer = snowball.SnowballStemmer(\"english\")\n",
    "tf[\"preprocessed\"] = tf[\"preprocessed\"].apply(lambda doc_tokens: [sstemmer.stem(x) for x in doc_tokens])\n",
    "tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, can apply a `Counter` to the preprocessed tokens in `tf` to get token counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>texts</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>term_freqs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 17:24:00</td>\n",
       "      <td>A second man has died as a result of heavy flo...</td>\n",
       "      <td>[second, man, die, result, heavi, flood, scotl...</td>\n",
       "      <td>{'second': 1, 'man': 5, 'die': 2, 'result': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 18:37:00</td>\n",
       "      <td>As tensions continue in Chicago over the handl...</td>\n",
       "      <td>[tension, continu, chicago, handl, polic, shoo...</td>\n",
       "      <td>{'tension': 1, 'continu': 1, 'chicago': 7, 'ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 22:01:00</td>\n",
       "      <td>Academic journals have begun withholding the g...</td>\n",
       "      <td>[academ, journal, begun, withhold, geograph, l...</td>\n",
       "      <td>{'academ': 2, 'journal': 4, 'begun': 1, 'withh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04 00:50:00</td>\n",
       "      <td>The brutal propaganda video released by Islami...</td>\n",
       "      <td>[brutal, propaganda, video, relea, islam, stat...</td>\n",
       "      <td>{'brutal': 1, 'propaganda': 7, 'video': 13, 'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-04 10:59:00</td>\n",
       "      <td>A cache of 13 weapons has been discovered in t...</td>\n",
       "      <td>[cach, weapon, discov, possess, gunman, open, ...</td>\n",
       "      <td>{'cach': 1, 'weapon': 4, 'discov': 1, 'possess...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime                                              texts  \\\n",
       "0 2016-01-01 17:24:00  A second man has died as a result of heavy flo...   \n",
       "1 2016-01-01 18:37:00  As tensions continue in Chicago over the handl...   \n",
       "2 2016-01-01 22:01:00  Academic journals have begun withholding the g...   \n",
       "3 2016-01-04 00:50:00  The brutal propaganda video released by Islami...   \n",
       "4 2016-01-04 10:59:00  A cache of 13 weapons has been discovered in t...   \n",
       "\n",
       "                                        preprocessed  \\\n",
       "0  [second, man, die, result, heavi, flood, scotl...   \n",
       "1  [tension, continu, chicago, handl, polic, shoo...   \n",
       "2  [academ, journal, begun, withhold, geograph, l...   \n",
       "3  [brutal, propaganda, video, relea, islam, stat...   \n",
       "4  [cach, weapon, discov, possess, gunman, open, ...   \n",
       "\n",
       "                                          term_freqs  \n",
       "0  {'second': 1, 'man': 5, 'die': 2, 'result': 1,...  \n",
       "1  {'tension': 1, 'continu': 1, 'chicago': 7, 'ha...  \n",
       "2  {'academ': 2, 'journal': 4, 'begun': 1, 'withh...  \n",
       "3  {'brutal': 1, 'propaganda': 7, 'video': 13, 'r...  \n",
       "4  {'cach': 1, 'weapon': 4, 'discov': 1, 'possess...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "tf[\"term_freqs\"] = tf[\"preprocessed\"].map(Counter)\n",
    "tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a document feature matrix (DFM)\n",
    "\n",
    "We will now create a document feature matrix (DFM). We will use tools in `sklearn` to create a DFM in a sparse matrix format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 552004 stored elements and shape (1959, 33975)>\n",
      "  Coords\tValues\n",
      "  (0, 91)\t2.0\n",
      "  (0, 118)\t2.0\n",
      "  (0, 204)\t1.0\n",
      "  (0, 261)\t2.0\n",
      "  (0, 289)\t1.0\n",
      "  (0, 470)\t4.0\n",
      "  (0, 513)\t1.0\n",
      "  (0, 597)\t2.0\n",
      "  (0, 815)\t3.0\n",
      "  (0, 939)\t1.0\n",
      "  (0, 940)\t1.0\n",
      "  (0, 970)\t1.0\n",
      "  (0, 1020)\t1.0\n",
      "  (0, 1625)\t5.0\n",
      "  (0, 1956)\t1.0\n",
      "  (0, 2333)\t1.0\n",
      "  (0, 2343)\t1.0\n",
      "  (0, 2479)\t3.0\n",
      "  (0, 2565)\t1.0\n",
      "  (0, 2702)\t1.0\n",
      "  (0, 2759)\t1.0\n",
      "  (0, 3407)\t2.0\n",
      "  (0, 3535)\t1.0\n",
      "  (0, 3699)\t1.0\n",
      "  (0, 3844)\t1.0\n",
      "  :\t:\n",
      "  (1958, 30119)\t1.0\n",
      "  (1958, 30133)\t3.0\n",
      "  (1958, 30181)\t1.0\n",
      "  (1958, 30265)\t1.0\n",
      "  (1958, 30328)\t1.0\n",
      "  (1958, 30385)\t4.0\n",
      "  (1958, 30393)\t1.0\n",
      "  (1958, 30435)\t1.0\n",
      "  (1958, 30751)\t1.0\n",
      "  (1958, 31017)\t1.0\n",
      "  (1958, 31152)\t1.0\n",
      "  (1958, 31949)\t2.0\n",
      "  (1958, 31972)\t2.0\n",
      "  (1958, 32542)\t1.0\n",
      "  (1958, 32557)\t1.0\n",
      "  (1958, 32608)\t1.0\n",
      "  (1958, 32703)\t1.0\n",
      "  (1958, 32752)\t3.0\n",
      "  (1958, 32812)\t3.0\n",
      "  (1958, 32850)\t2.0\n",
      "  (1958, 33008)\t1.0\n",
      "  (1958, 33393)\t9.0\n",
      "  (1958, 33451)\t1.0\n",
      "  (1958, 33459)\t3.0\n",
      "  (1958, 33657)\t1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1959, 33975)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer()\n",
    "dfm = dv.fit_transform(tf[\"term_freqs\"].to_list())\n",
    "print(dfm)\n",
    "dfm.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also be sure to extract and preserve the vocabulary from the `DictVectorizer` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'would'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = dv.get_feature_names_out()\n",
    "vocabulary[33459]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimming the DFM\n",
    "\n",
    "Notice that the DFM has over 34,000 features. This is a _very_ sparse DFM. We will want to reduce its size by \"trimming\" it to remove features (i.e., weight them by zero). We will use the recommendation in [this tutorial](https://tutorials.quanteda.io/machine-learning/topicmodel/) and only keep features that are both (1) in the top 20% of total term frequency, and (2) used in no more than 10% of documents. Note that we are trimming the DFM using a similar intuition as tf-idf weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1959, 6202)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttf = dfm.sum(axis = 0).A1 #研究一下A1什么意思\n",
    "docf = (dfm > 0).sum(axis=0).A1\n",
    "\n",
    "import numpy as np\n",
    "ttf_cutoff = np.quantile(ttf, 0.80)\n",
    "docf_cutoff = dfm.shape[0] * 0.1\n",
    "\n",
    "dfm = dfm[:, (ttf >= ttf_cutoff) & (docf <= docf_cutoff)] #不太确定咋回事这个地方 review needed\n",
    "dfm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: while we have trimmed the DFM, we have _not_ yet trimmed the corresponding `vocabulary` object, which we do next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly look at the top 20 features in this DFM to get a sense of how words are used in this corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a wordcloud object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll plot the wordcloud object using `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created this DFM, let's save it for further use. We'll also save the corpus file as well, so that we can access the texts if/when needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lse-my459",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
