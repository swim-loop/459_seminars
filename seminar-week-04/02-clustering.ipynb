{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar Notebook 2.2: Clustering\n",
    "\n",
    "**LSE MY459: Computational Text Analysis and Large Language Models** (WT 2026)\n",
    "\n",
    "**Ryan HÃ¼bert**\n",
    "\n",
    "This notebook covers the vector space approach and $k$-means clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory management\n",
    "\n",
    "We begin with some directory management to specify the file path to the folder on your computer where you wish to store data for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "sdir = os.path.join(os.path.expanduser(\"~\"), \"LSE-MY459-WT26\", \"SeminarWeek04\") # or whatever path you want\n",
    "if not os.path.exists(sdir):\n",
    "    os.mkdir(sdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the DFM\n",
    "\n",
    "We need to load the DFM we created in the last notebook. We start by reading the sparse array object we saved as an `.npz` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1959, 6236)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "sparse_dfm_file = os.path.join(sdir, 'guardian-dfm.npz')\n",
    "if os.path.exists(sparse_dfm_file):\n",
    "    dfm = sparse.load_npz(sparse_dfm_file)\n",
    "else:\n",
    "    raise ValueError(\"You must create the DFM using the previous notebook before proceeding!\")\n",
    "\n",
    "dfm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load the list of features (the vocabulary), which remember is not included with the sparse array data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = os.path.join(sdir, 'guardian-dfm-features.txt')\n",
    "vocabulary = open(features_file, mode = \"r\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating distance and similarity\n",
    "\n",
    "Before we look at $k$-means clustering, let's examine how to calculate distance and similarity between documents. First, we can calculate the Euclidean and Manhattan distances between documents using the formula from lecture. Let's calculate these two distance metrics between document 0 and document 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.553864678361276\n",
      "255.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ed = np.sqrt(((dfm[0] - dfm[1]).power(2)).sum())\n",
    "print(ed)\n",
    "\n",
    "md = np.abs(dfm[0] - dfm[1]).sum()\n",
    "print(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a convenient function available in `sklearn` for calculating distance. This function allows you to choose which metric you want to use, and it allows you to calculate distance between all documents (returning a matrix of pairwise distances). Let's calculate Euclidean and Manhattan distance between the first five documents. Note that Manhattan distance is called `cityblock` in `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         25.55386468 31.33687923 33.60059523 32.92415527]\n",
      " [25.55386468  0.         29.20616373 30.88689042 29.78254522]\n",
      " [31.33687923 29.20616373  0.         36.29049462 36.22154055]\n",
      " [33.60059523 30.88689042 36.29049462  0.         37.72267223]\n",
      " [32.92415527 29.78254522 36.22154055 37.72267223  0.        ]]\n",
      "[[  0. 255. 334. 329. 422.]\n",
      " [255.   0. 289. 272. 367.]\n",
      " [334. 289.   0. 359. 466.]\n",
      " [329. 272. 359.   0. 453.]\n",
      " [422. 367. 466. 453.   0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "edist = pairwise_distances(dfm[0:5], metric=\"euclidean\")\n",
    "print(edist)\n",
    "\n",
    "mdist = pairwise_distances(dfm[0:5], metric=\"cityblock\")\n",
    "print(mdist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the cosine similarity between two documents. For example, let's look at document 0 and 1. As we can see, they are not very similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01239644]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[89.28971795]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cs = cosine_similarity(dfm[0], dfm[1])  # cosine similarity\n",
    "print(cs)\n",
    "np.arccos(cs)                           # radians between documents\n",
    "np.degrees(np.arccos(cs))               # degrees between documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means Clustering\n",
    "\n",
    "First, we will weight the DFM using TF-IDF weighting. Note that, by default, `TfidfTransformer` applies a normalisation to ensure that all of the vectors in the DFM have the same magnitude. The default is to apply the L2 norm, which is another way of saying the vector for each row is normalised by its vector magnitude. This is exactly what we did when we computed cosine similarity in week 3 lecture. This normalisation removes differences due purely to document length, allowing clustering to focus on differences in word composition rather than scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "dfm_tfidf = transformer.fit_transform(dfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will \"set up\" our $k$-means clustering exercise. For now, let's try to find 30 clusters and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "K = 10\n",
    "kmeans = KMeans(n_clusters=K, random_state=42) \n",
    "labels = kmeans.fit_predict(dfm_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What objects can we extract from this? We are interested in each document $i$'s cluster assignment $\\widehat{\\boldsymbol{\\pi}}_i$, as well as each cluster $k$'s \"word usage\" as represented by the centroid $\\widehat{\\boldsymbol{\\mu}}_k$. Where can we extract those quantities from the `kmeans` and/or `labels` objects? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster assignment \n",
    "\n",
    "This gives you the cluster assignments for each document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 5 9 ... 2 5 9]\n"
     ]
    }
   ],
   "source": [
    "cluster_assignments = labels\n",
    "print(cluster_assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we see that document 0 is in cluster 3. This means: $\\widehat{\\boldsymbol{\\pi}}_0 = (0,0,1,0,0,0,0,0,0,0)$. (Remember: Python uses zero-indexing.) Let's now look at the distribution of documents across all clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_count</th>\n",
       "      <th>doc_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>0.026034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "      <td>0.047984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>0.055641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161</td>\n",
       "      <td>0.082185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221</td>\n",
       "      <td>0.112813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>701</td>\n",
       "      <td>0.357836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111</td>\n",
       "      <td>0.056662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>74</td>\n",
       "      <td>0.037774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>95</td>\n",
       "      <td>0.048494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>342</td>\n",
       "      <td>0.174579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_count  doc_prop\n",
       "0         51  0.026034\n",
       "1         94  0.047984\n",
       "2        109  0.055641\n",
       "3        161  0.082185\n",
       "4        221  0.112813\n",
       "5        701  0.357836\n",
       "6        111  0.056662\n",
       "7         74  0.037774\n",
       "8         95  0.048494\n",
       "9        342  0.174579"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cf = pd.Series(labels).value_counts()\n",
    "cf = pd.concat([cf, cf / cf.sum()], axis = 1, keys=[\"doc_count\", \"doc_prop\"])\n",
    "cf = cf.sort_index()\n",
    "cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster centroid feature use\n",
    "\n",
    "The following gives you a $K \\times J$ matrix (in our case $10 \\times 6236$) of cluster centroids, $\\widehat{\\boldsymbol{\\mu}}$. Each row is a specific cluster $k$'s \"average document\", which we can interpret as representing the cluster's prototypical word usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.00068003 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.00039359 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.00213422 0.         ... 0.00296132 0.         0.        ]]\n",
      "(10, 6236)\n"
     ]
    }
   ],
   "source": [
    "mu = kmeans.cluster_centers_\n",
    "print(mu)\n",
    "print(mu.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at a specific cluster's centroid by extracting a row of this matrix, such as cluster 0 (the \"first\" cluster):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], shape=(6236,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each cluster, we can use the cluster's row in `mu` to find the top words of that cluster. More specifically, the words used the most in the cluster's centroid. Consider cluster 0. First, let's figure out which of the elements of $\\boldsymbol{\\mu}_0$ represent the 6 most used words in this cluster's centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1230    0.352404\n",
      "2940    0.105353\n",
      "4926    0.085610\n",
      "5633    0.070186\n",
      "3128    0.069196\n",
      "3430    0.066686\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# How many \"top words\" do we want?\n",
    "num_top_feats = 6\n",
    "\n",
    "# Convert a row of mu to a Series object \n",
    "tf = pd.Series(mu[0]) \n",
    "# Get the top features (along with indexes)\n",
    "tf = tf.nlargest(num_top_feats)\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the _tokens_ that correspond to these `mu[0]` values, and then bind it as a column to `tf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mu0_j</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>0.352404</td>\n",
       "      <td>corbyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>0.105353</td>\n",
       "      <td>jeremi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4926</th>\n",
       "      <td>0.085610</td>\n",
       "      <td>shadow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5633</th>\n",
       "      <td>0.070186</td>\n",
       "      <td>tori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>0.069196</td>\n",
       "      <td>leadership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>0.066686</td>\n",
       "      <td>mcdonnel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mu0_j           j\n",
       "1230  0.352404      corbyn\n",
       "2940  0.105353      jeremi\n",
       "4926  0.085610      shadow\n",
       "5633  0.070186        tori\n",
       "3128  0.069196  leadership\n",
       "3430  0.066686    mcdonnel"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words = pd.Series([vocabulary[x] for x in tf.index], index=tf.index)\n",
    "tf = pd.concat([tf, top_words], axis=1, keys=[\"mu0_j\", \"j\"])\n",
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can do this for each of the clusters to get a general sense for what they are about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 top words: corbyn, jeremi, shadow, tori, leadership, mcdonnel\n",
      "Cluster 1 top words: syria, syrian, isi, refuge, un, saudi\n",
      "Cluster 2 top words: oil, uncertainti, inflat, pound, investor, forecast\n",
      "Cluster 3 top words: hospit, doctor, nhs, patient, shoot, junior\n",
      "Cluster 4 top words: johnson, refuge, migrant, bori, tori, khan\n",
      "Cluster 5 top words: drug, violenc, sexual, girl, obama, prison\n",
      "Cluster 6 top words: clinton, sander, cruz, hillari, rubio, berni\n",
      "Cluster 7 top words: turnbul, labor, australian, shorten, coalit, malcolm\n",
      "Cluster 8 top words: retail, store, bhs, profit, pension, properti\n",
      "Cluster 9 top words: climat, appl, energi, water, googl, food\n"
     ]
    }
   ],
   "source": [
    "tf = pd.DataFrame(mu) \n",
    "tf = tf.apply(pd.Series.nlargest, n=num_top_feats, axis=1)\n",
    "tf = tf.reset_index().melt(id_vars=\"index\", var_name=\"j\", value_name=\"mu_kj\").rename(columns={\"index\": \"cluster\"})\n",
    "tf = tf.dropna(subset=[\"mu_kj\"])\n",
    "tf = tf.sort_values([\"cluster\", \"mu_kj\"], ascending=[True, False])\n",
    "tf = tf.reset_index(drop=True)\n",
    "tf[\"feature\"] = [vocabulary[x] for x in tf[\"j\"]]\n",
    "\n",
    "top_words = tf.groupby(\"cluster\")[\"feature\"].apply(lambda s: \", \".join(s.astype(str)))\n",
    "\n",
    "for i,r in top_words.items():\n",
    "    print(f\"Cluster {i} top words: {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating clusters discriminating words\n",
    "\n",
    "We can also calculate the discriminating words of each cluster using `sklearn`'s function `chi2`, which calculate the Pearson's chi2 statistic from lecture 3. Let's start by doing it for one cluster to see the basic process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cluster        feature          chi2           pval\n",
      "1230        0         corbyn  12874.298157   0.000000e+00\n",
      "2940        0         jeremi   2633.643749   0.000000e+00\n",
      "4926        0         shadow   2037.390067   0.000000e+00\n",
      "3430        0       mcdonnel   1493.286777   0.000000e+00\n",
      "5701        0        trident   1345.861385  1.221888e-294\n",
      "...       ...            ...           ...            ...\n",
      "5640        0          tough      0.000013   9.971378e-01\n",
      "6070        0         weight      0.000011   9.973766e-01\n",
      "4574        0          remot      0.000011   9.973766e-01\n",
      "4542        0         regret      0.000011   9.973766e-01\n",
      "1986        0  extraordinari      0.000011   9.973766e-01\n",
      "\n",
      "[6236 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "target = cluster_assignments == 0  # cluster 0 versus all other clusters\n",
    "scores, pvals = chi2(dfm, target)  # chi2 against null hypothesis (for all features at once)\n",
    "\n",
    "# Now let's format nicely\n",
    "disc_words = pd.DataFrame({\"cluster\": 0, \"feature\": vocabulary, \"chi2\" : scores, \"pval\" : pvals})\n",
    "disc_words = disc_words.sort_values(\"chi2\", ascending=False)\n",
    "print(disc_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot a bar chart depicting the top 10 most discriminating words for cluster 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top = disc_words.nlargest(10, \"chi2\").sort_values(\"chi2\")\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.barh(top[\"feature\"], top[\"chi2\"])\n",
    "plt.xlabel(\"Chi-square statistic\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"Most indicative features of cluster 0\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we do it for all clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 most discriminating words: corbyn, jeremi, shadow, mcdonnel, trident, leadership\n",
      "Cluster 1 most discriminating words: syria, isi, syrian, aleppo, saudi, humanitarian\n",
      "Cluster 2 most discriminating words: oil, pound, crude, investor, output, opec\n",
      "Cluster 3 most discriminating words: doctor, nhs, hospit, patient, junior, isra\n",
      "Cluster 4 most discriminating words: migrant, refuge, johnson, khan, brake, tusk\n",
      "Cluster 5 most discriminating words: clinton, sander, drug, sexual, prison, abus\n",
      "Cluster 6 most discriminating words: clinton, sander, cruz, hillari, berni, ted\n",
      "Cluster 7 most discriminating words: turnbul, labor, shorten, malcolm, australian, abbott\n",
      "Cluster 8 most discriminating words: retail, bhs, landlord, mortgag, pension, tenant\n",
      "Cluster 9 most discriminating words: climat, appl, googl, energi, app, iphon\n"
     ]
    }
   ],
   "source": [
    "dwf = pd.DataFrame()\n",
    "\n",
    "for cluster in range(K):\n",
    "    target = cluster_assignments == cluster\n",
    "    scores, pvals = chi2(dfm, target)\n",
    "    disc_words = pd.DataFrame({\"cluster\": cluster, \"feature\": vocabulary, \"chi2\" : scores, \"pval\" : pvals})\n",
    "    disc_words = disc_words.sort_values(\"chi2\", ascending=False).iloc[0:num_top_feats,:]\n",
    "    disc_words = disc_words.loc[disc_words[\"pval\"] < 0.05,:]\n",
    "    dwf = pd.concat([dwf, disc_words], axis = 0)\n",
    "\n",
    "disc_words = dwf.groupby(\"cluster\")[\"feature\"].apply(lambda s: \", \".join(s.astype(str)))\n",
    "\n",
    "for i,r in disc_words.items():\n",
    "    print(f\"Cluster {i} most discriminating words: {r}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lse-my459",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
