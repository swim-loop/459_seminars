{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar Notebook 2.4: Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "**LSE MY459: Computational Text Analysis and Large Language Models** (WT 2026)\n",
    "\n",
    "**Ryan HÃ¼bert**\n",
    "\n",
    "This notebook covers Latent Dirichlet Allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory management\n",
    "\n",
    "We begin with some directory management to specify the file path to the folder on your computer where you wish to store data for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "sdir = os.path.join(os.path.expanduser(\"~\"), \"LSE-MY459-WT26\", \"SeminarWeek04\") # or whatever path you want\n",
    "if not os.path.exists(sdir):\n",
    "    os.mkdir(sdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the DFM\n",
    "\n",
    "We need to load the DFM we created in the last notebook. We start by reading the sparse array object we saved as an `.npz` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1959, 6236)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "\n",
    "sparse_dfm_file = os.path.join(sdir, 'guardian-dfm.npz')\n",
    "if os.path.exists(sparse_dfm_file):\n",
    "    dfm = sparse.load_npz(sparse_dfm_file)\n",
    "else:\n",
    "    raise ValueError(\"You must create the DFM using the previous notebook before proceeding!\")\n",
    "\n",
    "dfm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load the list of features (the vocabulary), which remember is not included with the sparse array data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = os.path.join(sdir, 'guardian-dfm-features.txt')\n",
    "vocabulary = open(features_file, mode = \"r\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "We will run LDA on our corpus of news articles. We'll estimate 10 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "K = 10\n",
    "lda = LatentDirichletAllocation(n_components=K, random_state=6541)\n",
    "lda = lda.fit(dfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was the case for $k$-means clustering, we are interested in each document $i$'s $\\widehat{\\boldsymbol{\\pi}}_i$, as well as each cluster $k$'s $\\widehat{\\boldsymbol{\\mu}}_k$. However in the context of topic modelling, they have different interpretations:\n",
    "\n",
    "- $\\widehat{\\boldsymbol{\\pi}}_i$ gives the proportion of document $i$ that corresponds to each topic\n",
    "- $\\widehat{\\boldsymbol{\\mu}}_k$ gives the word use for a topic $k$\n",
    "\n",
    "Where can we extract these important items from the `lda` object?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic assignment proportions \n",
    "\n",
    "We can extract each document's topic proportions as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.09087177e-01, 6.45250311e-04, 6.45298651e-04, ...,\n",
       "        3.45914315e-01, 6.45304265e-04, 6.45290131e-04],\n",
       "       [9.61627750e-04, 9.69995121e-01, 9.61787655e-04, ...,\n",
       "        9.61712693e-04, 2.23112091e-02, 9.61727355e-04],\n",
       "       [5.80502988e-01, 5.29241921e-04, 5.29182746e-04, ...,\n",
       "        3.27037817e-01, 5.29211071e-04, 5.29226236e-04],\n",
       "       ...,\n",
       "       [4.16779291e-04, 4.16730470e-04, 4.16777639e-04, ...,\n",
       "        4.16710758e-04, 4.16792021e-04, 4.16730949e-04],\n",
       "       [7.75462038e-02, 4.15030516e-04, 4.15106098e-04, ...,\n",
       "        3.05189661e-01, 4.15089298e-04, 4.15082475e-04],\n",
       "       [7.41013871e-04, 7.40904474e-04, 2.44583503e-02, ...,\n",
       "        5.34036348e-01, 7.40923013e-04, 7.40898063e-04]], shape=(1959, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = lda.transform(dfm)\n",
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we see that document 0 has the following proportions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40908718, 0.00064525, 0.0006453 , 0.24048126, 0.0006454 ,\n",
       "       0.00064535, 0.00064536, 0.34591431, 0.0006453 , 0.00064529])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document is 40% about topic 0, 24% about topic 3, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic feature probabilities (word use)\n",
    "\n",
    "Next, we need to examine what these topics are actually about. We begin by extracting a $K \\times J$ matrix (in our case $10 \\times 6236$), where each row gives a topic's $\\widehat{\\boldsymbol{\\mu}}_k$. In the DGP for LDA, this parameter controls the probabilities that each token in the vocabulary will be chosen when a token is assigned to that topic. The following code extracts this $\\widehat{\\boldsymbol{\\mu}}$ matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.84452025e-06, 6.49441088e-06, 2.84452025e-06, ...,\n",
       "        2.84478316e-06, 2.84452025e-06, 2.84452025e-06],\n",
       "       [3.74060841e-06, 4.41948993e-05, 3.77800874e-04, ...,\n",
       "        3.74138134e-06, 1.90964808e-04, 3.74132293e-06],\n",
       "       [3.32516647e-06, 1.52858306e-04, 3.32538213e-06, ...,\n",
       "        3.32528809e-06, 1.66295166e-04, 3.32516647e-06],\n",
       "       ...,\n",
       "       [2.11580965e-06, 7.44144449e-05, 2.11587431e-06, ...,\n",
       "        3.47730874e-06, 2.11580965e-06, 2.11580965e-06],\n",
       "       [1.93600198e-06, 2.59673184e-04, 1.93600198e-06, ...,\n",
       "        1.93625416e-06, 1.13141448e-05, 1.93600198e-06],\n",
       "       [6.13496955e-04, 2.18338150e-06, 2.18326321e-06, ...,\n",
       "        2.18327132e-06, 2.18556113e-06, 2.42341799e-04]], shape=(10, 6236))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = lda.components_ / lda.components_.sum(axis=1, keepdims=True)\n",
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a specific topic's word usage by extracting a row of this matrix, such as topic 0 (the \"first\" topic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.84452025e-06, 6.49441088e-06, 2.84452025e-06, ...,\n",
       "       2.84478316e-06, 2.84452025e-06, 2.84452025e-06], shape=(6236,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each topic, we can use the topic's row in `mu` to find the top words of that cluster. More specifically, the words used the most in the cluster's centroid. Consider cluster 0. First, let's figure out which of the elements of $\\boldsymbol{\\mu}_0$ represent the 6 most used words in this cluster's centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013    0.012126\n",
      "6047    0.010213\n",
      "1836    0.009952\n",
      "2154    0.009389\n",
      "2277    0.005840\n",
      "4625    0.005070\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# How many \"top words\" do we want?\n",
    "num_top_feats = 6\n",
    "\n",
    "# Convert a row of mu to a Series object \n",
    "tf = pd.Series(mu[0]) \n",
    "# Get the top features (along with indexes)\n",
    "tf = tf.nlargest(num_top_feats)\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know what each of the 10 topics are roughly about. So we can look at the top features for each topic $k$, as represented by the feature with the highest probability in $\\boldsymbol{\\mu}_k$. This is identical to what we did for $k$-means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 top words: climat, water, energi, food, gas, retail\n",
      "Topic 1 top words: violenc, arrest, assault, shoot, sentenc, murder\n",
      "Topic 2 top words: clinton, sander, gun, hillari, berni, deleg\n",
      "Topic 3 top words: australian, labor, turnbul, coalit, malcolm, shorten\n",
      "Topic 4 top words: oil, investor, quarter, analyst, stock, china\n",
      "Topic 5 top words: corbyn, jeremi, shadow, leadership, resign, de\n",
      "Topic 6 top words: johnson, game, appl, osborn, googl, tori\n",
      "Topic 7 top words: doctor, drug, hospit, medic, prison, patient\n",
      "Topic 8 top words: cruz, obama, rubio, clinton, sander, ted\n",
      "Topic 9 top words: refuge, syria, syrian, brussel, isi, turkey\n"
     ]
    }
   ],
   "source": [
    "tf = pd.DataFrame(mu) \n",
    "tf = tf.apply(pd.Series.nlargest, n=num_top_feats, axis=1)\n",
    "tf = tf.reset_index().melt(id_vars=\"index\", var_name=\"j\", value_name=\"mu_kj\").rename(columns={\"index\": \"topic\"})\n",
    "tf = tf.dropna(subset=[\"mu_kj\"])\n",
    "tf = tf.sort_values([\"topic\", \"mu_kj\"], ascending=[True, False])\n",
    "tf = tf.reset_index(drop=True)\n",
    "tf[\"feature\"] = [vocabulary[x] for x in tf[\"j\"]]\n",
    "\n",
    "top_words = tf.groupby(\"topic\")[\"feature\"].apply(lambda s: \", \".join(s.astype(str)))\n",
    "\n",
    "for i,r in top_words.items():\n",
    "    print(f\"Topic {i} top words: {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading documents\n",
    "\n",
    "Of course, if you want to really understand these topics, you will need to read a selection of documents corresponding to each one of the topics. Let's look at the five documents that have the highest proportion of tokens assigned to a topic. First, let's identify the top five documents for each topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.997196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997680</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997493</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997493</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.996819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997606</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>0.996086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>0.996086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>0.996564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.997457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "9          NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "34         NaN  0.995477       NaN       NaN       NaN       NaN       NaN   \n",
       "128        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "248   0.997196       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "268        NaN       NaN       NaN       NaN  0.997105       NaN       NaN   \n",
       "309        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "350        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "362        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "379        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "401        NaN       NaN       NaN  0.996470       NaN       NaN       NaN   \n",
       "438        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "449        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "450        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "465   0.996819       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "492        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "521        NaN       NaN  0.998943       NaN       NaN       NaN       NaN   \n",
       "537        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "539        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "543        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "766        NaN  0.994856       NaN       NaN       NaN       NaN       NaN   \n",
       "786        NaN       NaN       NaN       NaN       NaN       NaN  0.996702   \n",
       "836        NaN       NaN       NaN       NaN  0.998245       NaN       NaN   \n",
       "849        NaN       NaN  0.999117       NaN       NaN       NaN       NaN   \n",
       "867        NaN       NaN       NaN       NaN  0.997513       NaN       NaN   \n",
       "869        NaN       NaN       NaN       NaN  0.997826       NaN       NaN   \n",
       "893        NaN       NaN       NaN  0.997940       NaN       NaN       NaN   \n",
       "897        NaN       NaN       NaN  0.998937       NaN       NaN       NaN   \n",
       "899        NaN       NaN       NaN       NaN  0.997345       NaN       NaN   \n",
       "918        NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "986        NaN       NaN  0.998839       NaN       NaN       NaN       NaN   \n",
       "989        NaN       NaN  0.999185       NaN       NaN       NaN       NaN   \n",
       "991        NaN       NaN  0.999360       NaN       NaN       NaN       NaN   \n",
       "1132       NaN       NaN       NaN  0.996678       NaN       NaN       NaN   \n",
       "1136       NaN       NaN       NaN  0.996370       NaN       NaN       NaN   \n",
       "1202  0.996086       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1204  0.996086       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1215  0.996564       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1217       NaN  0.996896       NaN       NaN       NaN       NaN       NaN   \n",
       "1240       NaN       NaN       NaN       NaN       NaN  0.997313       NaN   \n",
       "1241       NaN       NaN       NaN       NaN       NaN  0.997280       NaN   \n",
       "1318       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1467       NaN  0.997799       NaN       NaN       NaN       NaN       NaN   \n",
       "1510       NaN       NaN       NaN       NaN       NaN  0.996295       NaN   \n",
       "1512       NaN       NaN       NaN       NaN       NaN  0.996428       NaN   \n",
       "1514       NaN       NaN       NaN       NaN       NaN       NaN  0.998809   \n",
       "1721       NaN       NaN       NaN       NaN       NaN       NaN  0.997087   \n",
       "1773       NaN       NaN       NaN       NaN       NaN  0.998602       NaN   \n",
       "1869       NaN  0.994914       NaN       NaN       NaN       NaN       NaN   \n",
       "1909       NaN       NaN       NaN       NaN       NaN       NaN  0.998101   \n",
       "1921       NaN       NaN       NaN       NaN       NaN       NaN  0.997457   \n",
       "\n",
       "             7         8         9  \n",
       "9          NaN       NaN  0.998056  \n",
       "34         NaN       NaN       NaN  \n",
       "128   0.997221       NaN       NaN  \n",
       "248        NaN       NaN       NaN  \n",
       "268        NaN       NaN       NaN  \n",
       "309   0.995521       NaN       NaN  \n",
       "350        NaN  0.997680       NaN  \n",
       "362        NaN  0.999250       NaN  \n",
       "379        NaN       NaN  0.999398  \n",
       "401        NaN       NaN       NaN  \n",
       "438   0.995384       NaN       NaN  \n",
       "449        NaN  0.997493       NaN  \n",
       "450        NaN  0.997493       NaN  \n",
       "465        NaN       NaN       NaN  \n",
       "492        NaN  0.997606       NaN  \n",
       "521        NaN       NaN       NaN  \n",
       "537        NaN       NaN  0.996484  \n",
       "539        NaN       NaN  0.997450  \n",
       "543        NaN       NaN  0.996938  \n",
       "766        NaN       NaN       NaN  \n",
       "786        NaN       NaN       NaN  \n",
       "836        NaN       NaN       NaN  \n",
       "849        NaN       NaN       NaN  \n",
       "867        NaN       NaN       NaN  \n",
       "869        NaN       NaN       NaN  \n",
       "893        NaN       NaN       NaN  \n",
       "897        NaN       NaN       NaN  \n",
       "899        NaN       NaN       NaN  \n",
       "918   0.997606       NaN       NaN  \n",
       "986        NaN       NaN       NaN  \n",
       "989        NaN       NaN       NaN  \n",
       "991        NaN       NaN       NaN  \n",
       "1132       NaN       NaN       NaN  \n",
       "1136       NaN       NaN       NaN  \n",
       "1202       NaN       NaN       NaN  \n",
       "1204       NaN       NaN       NaN  \n",
       "1215       NaN       NaN       NaN  \n",
       "1217       NaN       NaN       NaN  \n",
       "1240       NaN       NaN       NaN  \n",
       "1241       NaN       NaN       NaN  \n",
       "1318  0.994155       NaN       NaN  \n",
       "1467       NaN       NaN       NaN  \n",
       "1510       NaN       NaN       NaN  \n",
       "1512       NaN       NaN       NaN  \n",
       "1514       NaN       NaN       NaN  \n",
       "1721       NaN       NaN       NaN  \n",
       "1773       NaN       NaN       NaN  \n",
       "1869       NaN       NaN       NaN  \n",
       "1909       NaN       NaN       NaN  \n",
       "1921       NaN       NaN       NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_top_docs = 5\n",
    "zf = pd.DataFrame(pi) \n",
    "zf = zf.apply(pd.Series.nlargest, n=num_top_docs, axis=0)\n",
    "zf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load the corpus documents and look at the top five documents in topic 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-02-03 11:02:00\n",
      "('Human emissions of heat-trapping gases like carbon dioxide are causing the '\n",
      " 'Earth to warm. We know this, and we have known this would happen for over '\n",
      " '100 years. But scientists want to know how fast the Earth is ')\n",
      "\n",
      "\n",
      "2016-02-24 21:15:00\n",
      "('Right now, roughly a kilometre below the surface of an ocean near you, a '\n",
      " 'yellow cylinder about the size of a golf bag is taking measurements of the '\n",
      " 'temperature and saltiness of the water. | Every couple of days')\n",
      "\n",
      "\n",
      "2016-05-23 22:10:00\n",
      "(\"Sir Philip Green's retail business was warned before the sale of BHS that \"\n",
      " 'Dominic Chappell, the man who led the buyout, had been declared bankrupt and '\n",
      " 'lacked experience in the retail industry. | Paul Budge, the')\n",
      "\n",
      "\n",
      "2016-05-23 22:30:00\n",
      "(\"Sir Philip Green's retail business was warned before the sale of BHS that \"\n",
      " 'Dominic Chappell, the man who led the buyout, had been declared bankrupt and '\n",
      " 'lacked experience in the retail industry. | Paul Budge, the')\n",
      "\n",
      "\n",
      "2016-05-24 17:20:00\n",
      "('Anti-fracking campaigners have accused North Yorkshire council of declaring '\n",
      " \"war on people's rights to clean air and water after it approved the first \"\n",
      " 'operation to frack for shale gas in five years. | Campaigner')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "topic = 0\n",
    "topic_idx = zf.iloc[:,topic].dropna().index\n",
    "\n",
    "corpus_file = os.path.join(sdir, 'guardian-corpus.csv')\n",
    "corpus = pd.read_csv(corpus_file)\n",
    "\n",
    "for i,r in corpus.iloc[topic_idx,:].iterrows():\n",
    "    print(r[\"datetime\"])\n",
    "    pprint(r[\"texts\"][0:210], width=80)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could, of course, do the same thing to review clusters as well!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lse-my459",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
